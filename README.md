DLITHE INTERNSHIP

This internship has trained  different analytics learning library like numpy, pandas, matplotlib and seaborn.
We also had a few classes in machine learning and statistics which help us analyze the given data.

Assignments during Online Internship with DLithe(www.dlithe.com).

Assignment 1

Fish Market 

Database of common fish species for fish market
This dataset is a record of 7 common different fish species in fish market sales. With this dataset, a predictive model can be performed using machine friendly data and estimate the weight of fish can be predicted.

Multiple linear regression is a fundamental practice for this dataset. Multivariate analysis can also be performed.

The dataset is from:https://www.kaggle.com/datasets/aungpyaeap/fish-market?resource=download

1.Spyder was used for Implementation

2.The libraries used are Pandas for data collection. Seaborn for Visualisation and data analysis. And sklearn for Machine learning algorithm selection.

3.The process starts with gathering the data from kaggle on Fish Market dataset.

4.Cleansing the data checking for any missing values. Removing the unwanted columns from dataset using drop command is part of data processing.

5.Selecting independent variables in x array i.e on species, weight,vertical length,diagonal length, cross length,height ,diagonal width. And dependent variables or target variable to y array i.e current price. Since the target variable is continuous Linear Regression is planned to be used for prediction.

6.Split universal dataset to FishMarket and testset using library sklearn,module:model_selection, class : Fish species in grams. Test size of 0.3 was used with random state of 350. The Fish Market was named x_Fish, y_fih and test set was assigned as x_test, y_test.

7.Linear regression was used as Algorithm Selection for training and predicting the y_test named as y_pred. Using the Library: sklearn, module : Linear_model, class : LinearRegression.

8.Checking the accuracy of y_fish and y_fish was done using the Library: sklearn, module : metrics, class : r2score

Assignment 2

Vehicle dataset

The data is got from:https://www.kaggle.com/datasets/mayankpatel14/second-hand-used-cars-data-set-linear-regression

1.Spyder was used for Implementation.

2.The libraries used are Pandas for data collection. Seaborn for Visualisation and data analysis. And sklearn for Machine learning algorithm selection.

3.The process starts with gathering the data from kaggle on secondhand car dataset.

4.Cleansing the data checking for any missing values. Removing the unwanted columns from dataset using drop command is part of data processing.

5.Selecting independent variables in x array i.e on road old, on road now, years, km, rating, condition,economy,top speed, hp, torque. And dependent variables or target variable to y array i.e current price. Since the target variable is continuous Linear Regression is planned to be used for prediction.

6.Split universal dataset to trainset and testset using library sklearn,module:model_selection, class : train_test_split. Test size of 0.3 was used with random state of 350. The train set was named x_train, y_train and test set was assigned as x_test, y_test.

7.Linear regression was used as Algorithm Selection for training and predicting the y_test named as y_pred. Using the Library: sklearn, module : Linear_model, class : LinearRegression.

8.Checking the accuracy of y_train andy_pred was done using the Library: sklearn, module : metrics, class : r2score


TECHNICAL INSTRUCTIONS

-> This file contains ipynb file since the code was built on jupyter.

-> Pandas, Numpy, Seaborn and Matplotlib are used for data analysis.

-> Reading the data was done through Pandas.

-> Data Cleaning was done through Pandas and Seaborn.

-> Data testing was done using Numpy.

-> This project was built on python.

-> The dataset is sourced from Kaggle.

-> The ending results of all questions are based on graphs which are done using matplotlib.




